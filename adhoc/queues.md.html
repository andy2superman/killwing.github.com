<!DOCTYPE html>
<html>
<meta charset="utf-8" />
<title>Queues</title>
<xmp theme="united" style="display:none;">
## Basic
消息投递可靠性：http://proto.actor/docs/durability
消息驱动vs事件驱动: http://www.reactivemanifesto.org/glossary#Message-Driven

## [NSQ](http://nsq.io/)
模型：
topic -> channel，每个channel都收到一个topic消息的copy (broadcast)
channel -> consumers, 每个consumers收到一个channel里的一部分消息（处理不同的消息）(load balanced)


消息保证：

* 消息可靠性：基于内存，超过阈值之后写入磁盘持久化。
    * --mem-queue-size can be set to 0 to to ensure that all incoming messages are persisted to disk.
    * stand up redundant nsqd pairs (on separate hosts) that receive copies of the same portion of messages.
* 消息多次投递（至少一次）：单nsqd实例通常不会发生，client负责等冪操作或去重。
* client收消息是无序的（不保证和投递顺序一样）。
* 消费者最终会找到所有topic的生产者。

消息接收：PUSH模型
RDY N: 表示可以接收N个消息，服务端然后推送
FIN/REQ：处理完成／重试（重入队列）
TOUCH: 重置消息超时（超时会重入队列重试）

Roadmap:
https://github.com/mreiferson/mreiferson.github.com/blob/nsq_roadmap_1/posts/nsq_roadmap.md

## [SQS](https://aws.amazon.com/cn/documentation/sqs/)
标准队列：

* 高性能，吞吐
* 消息顺序：尽可能保证有序
* 至少一次消息投递
* 消息接收：short/long polling
* 可以去重

FIFO:

* 性能有限
* 先进先出
* 有且仅有一次消息投递
* 不去重

![sqs](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/images/sqs-tutorials-creating-queue-queue-type-descriptions.png)

消息API:
SendMessage(Batch)
ReceiveMessage
DeleteMessage(Batch)
ChangeMessageVisibility(Batch)

ReceiptHandle: 每次收到消息的唯一ID（可能是重试的相同的消息），表示了一次接收的上下文（否则同一消息的重试就不能区分），用于后续操作。

## [Kafka](http://kafka.apache.org/)
流式订阅发布分布式系统。

* 以记录方式存储，以topic分类记录，每个记录包含key, value, timestamp。topic就是记录流。
* topic以分区log的形式组织，每个记录追加到分区的commit log上，并由seq id(offset)标识。消费者只根据分区级的offset来收取消息。
* 记录不管有没有消费都一直保持，直到保持时间过期。
* 如果设置了副本，每个分区都有一个leader节点负责读写，其它followers节点负责复制记录。一个节点可以同时是一个分区的leader，另一个分区的follower。
* 生产者决定发布在一个topic的记录如何分区以达到更好的性能。
* 对于订阅的topic，不同消费者组(即subscriber)消费同一个消息(broadcast)，同一个消费者组里的消费者消费不同的消息(load balanced)。这里LB是分区级别的，即把不同分区固定分配给一个组里的不同消费者，所以同组消费者实例不大于分区数量(实例的增减会导致重新分配)。

物理存储格式：

每个分区由多个 segment 组成，每个 segment  由多个 message 组成。

segment: index, log, timeindex 三个文件组成，文件名为起始 offset

* index: 保存了这个 segment 的稀疏 offset 和对应的物理位置（字节），所以只能定位到最近的 offset
* log: 数据文件，以 message 格式保存
* timeindex: 时间索引

message

* offset(8)
* size(4)
* CRC32(4)
* magic(1) 协议版本号
* attr(1) 压缩或编码类型
* len(4) key 长度
* key(len)
* payload(size)

## [Disqueue](https://github.com/antirez/disque)
Disque 只能在内存中操作，使用同步复制作为可靠性保证。
translate: http://mp.weixin.qq.com/s/gCgz5tfMw13XXQl3nfXkwg

## [Disruptor](https://lmax-exchange.github.io/disruptor/)
内存队列

## [Mongo queue](https://github.com/chilts/mongodb-queue)

## [zmq](http://zguide.zeromq.org/page:all)
### Request-Reply
client以发送请求、接收响应的次序`zmq_socket(context, ZMQ_REQ);`
server以接收请求，发送响应的次序`zmq_socket(context, ZMQ_REP);`
不按次序的操作会失败。
多个client可以连接同一个server，server会发送响应到收到请求的client。
默认socket都是blocking操作。

### Publish-Subscribe
server只发不收`zmq_socket(context, ZMQ_PUB);`
client只收不发`zmq_socket(context, ZMQ_SUB);`，订阅`zmq_setsockopt(subscriber, ZMQ_SUBSCRIBE, filter, strlen(filter));`前缀匹配，可以连多个server
一个server pub的消息会（复制）发送给每个sub的client。
一个client可以连多个server，sub不同的消息，收到的消息会交错。
client连接之前server发送的消息都会丢弃，连接之后会缓存放到server的queue里。
对于有连接协议，过滤是发生在server端。

### Push-Pull
`zmq_socket(context, ZMQ_PUSH);`
`zmq_socket(context, ZMQ_PULL);`
server push, client pull: push会等待连接（平均分配消息到所有连接上），但不等待pull，消息只会被消费(pull)一次。
server pull, client push: push不会等待pull，但消息不会丢弃。

### Dealer-Router
可以用DEALER/ROUTER（无协议）完全替代REQ/REP（有协议），这就必需自己定制协议：控制消息次序和格式。

例如：
将REQ/REP都作为client连到broker server上。
broker server作为`zmq_socket(context, ZMQ_DEALER);` `zmq_socket(context, ZMQ_ROUTER);`
ROUTER接收请求转发到后端，DEALER接收响应转发到前端。

## Reference
http://queues.io/
http://www.warski.org/blog/2014/07/evaluating-persistent-replicated-message-queues/
https://mp.weixin.qq.com/s?__biz=MzI5ODQ2MzI3NQ==&mid=2247486596&idx=1&sn=2fb2101063a5e62913d26cd031aeabe3
</xmp>
<script src="../js/strapdown.js"></script>
</html>
