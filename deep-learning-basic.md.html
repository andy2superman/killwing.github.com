<!DOCTYPE html>
<html>
<meta charset="utf-8" />
<title>Deep Learning Basic</title>
<xmp theme="readable" style="display:none;">
## Basic & MNIST
https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/

epoch: 完成一次：训练样本总数 N = 每个batch的样本数 b * 迭代次数 m。
神经元：在神经网络中，对一个样本的所有或部分输入加权求和（加上偏差），并用结果来调用一个非线性的激活函数，最后产生一个输出。每个神经元都对(一组)输入都对应一组权重，一个偏差值。
对于分类问题，一个常用的激活函数是softmax。
softmax: 值域[0, 1]，既能明显地表示出最大的元素，又能保持与其他元素的相对大小关系。
对于分类问题，一个常用的表示误差距离的是交叉熵cross-entropy。
cross-entropy (loss function): 所有元素的真实概率(one-hot，表示某个确切的值)和计算概率(softmax结果)的对数的乘积之和的负值。
one-hot: 只有一个元素值（概率）是1，其余值为0。
broadcasting: 当两个矩阵运算不满足纬度要求时，扩展（复制元素）纬度小的那个直到满足要求。
tensor: 一维tensor为向量，二维tensor为矩阵...
训练：每次迭代不断调整权重和偏差的值，利用gradient descent算法使cross-entropy最小（即真实概率为1的元素尽可能对应计算概率最大的那个元素）。
gradient descent：梯度下降，走最陡路径到一个最小值。
learning rate：梯度下降的幅度，来调整权重和偏差。太小则收敛速度慢，太大则会产生跳跃偏差。一般一开始使用一个较大值，随着迭代次数逐步减小（LR Decay）。
mini-batches：BGD，每次迭代用全部样本计算梯度，梯度会受限于不同的样本，平均最小化这批所有样本的损失函数，对整体而言收敛速度 更快，但计算量更大。只用一个样本称为随机梯度下降SGD(stochastic gradient descent)，随机性更强。通常是使用一批样本的SGD，样本数量即为batch size。

sigmoid：中间层的激活函数，1/(1+e^-x)，值域[0, 1]。层数过多会丢失信息（精度）。替代：Relu (Rectified Linear Unit)激活函数。
第一层的输入是样本值，中间层的输入是上一层的输出，中间层每层的权重和偏差都不一样，初始一般为随机值，神经元的数目自定义。
最后一层是softmax，神经元的数目为要识别分类的数目。


saddle points： 随着样本维数增多，权重和偏差数量巨大，经常出现使得梯度为0而不是真正最小值的点，-> 使用AdamOptimizer代替GradientDescentOptimiser。
overfitting（过拟合）: 表示学习效果不好，真实测试数据和训练数据结果相差很大，-> dropout：每次训练迭代随机丢弃一定的神经元（在全连接层）。(其他原因：训练数据太少，训练网络设计不好)

CNN:
一个神经元的输入不再是单一向量(图像变成一维丢失了形状信息)，而是一个区域（对于RGB图像是(M,N,3)的三维区域），而对应这块区域输入一般会采用多组权重，但对于不同区域重用相同的权重值。神经元的数目为权重的组数目×样本元素数目（像素）。
max-pool: 降采样，取区域中最大值。一般最大值（图像边缘）是最有用的信息。作用：提取特征，去噪。
full-connection: 全连接，连接变为一维向量。
stride: 卷积核滑动的步长。

### Sample Set
training set: 训练数据集（mnist: 60000, batch size: 64, iter: 1000/epoch）
validation set: 验证数据集，一般和训练同时进行，对训练没有影响，主要验证是否过拟合及时停止训练调整超参数，以得到更好的模型 （mnist: 10000, batch size: 100, iter: 100）
test set: 用于评估（evaluation）最终训练后的模型，预测（predict）结果


## Evaluation
### Precision & Recall
https://en.wikipedia.org/wiki/Precision_and_recall
准确率(A)：Accuracy。`A = (TP + TN)/(P+N) = (TP + TN)/(TP + FN + FP + TN)`
召回率(R)：Recall，又称“查全率”。没有漏查（漏报, Missing Alarm）。`R = TP/(TP+FN)`
精确率(P)：Precision。没有多查（误报, False Alarm）。`P = TP/(TP+FP)`
F1 Measure: `F1 = 2P*R / (P+R)`

比如：100张样本图片，真实有10张黄图，检测出8张黄图，其中6张是真实黄图(TP)，2张误报(FP)，4张漏报(FN)。
则：P = 6/8, R = 6/10, A = (6+88)/100

|       |实际真 |实际假
|-|-|-
|检测真 |6(TP)  |2(FP)
|检测假 |4(FN)  |88(TN)

PR曲线：对于一个类别，采用所有样本不同的推理score作为阈值（采点）下P和R的点图。
http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html

对于分类问题：根据 ground truth （实际真假） 和 推理结果及分数阈值来确定评估真假。
对于检测问题：根据 iou （重合度） 最大的组合及 iou 阈值确定 ground truth，根据这个组合的推理结果和分数阈值来确定评估真假。

### ROC
https://en.wikipedia.org/wiki/Receiver_operating_characteristic

真正例率：和Recall一样。`TPR = TP/(TP+FN)`
假真例率：把多少负样本也归成了正的了。`FPR = FP/(TN+FP)`

ROC(Receiver Operating Characteristic)曲线：对于一个类别，采用所有样本不同的推理score作为阈值（采点）下TPR和FPR的点图。
http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html

</xmp>
<script src="js/strapdown.js"></script>
</html>
