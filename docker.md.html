<!DOCTYPE html>
<html>
<title>Docker</title>
<xmp theme="readable" style="display:none;">
http://www.docker.com | v1.10

## Engine
### Install
ubuntu: `curl -fsSL https://get.docker.com/ | sh` (`curl -fsSL https://get.docker.com/gpg | sudo apt-key add -`)
arch: `pacman -S docker`; `systemctl enable/restart docker`
查看版本及状态：`docker version/info`

[daemon启动参数设置](https://docs.docker.com/engine/admin/systemd/)：`systemctl edit docker`
[设置最大task限制](http://unix.stackexchange.com/questions/253903/creating-threads-fails-with-resource-temporarily-unavailable-with-4-3-kernel/255603#)

### Image
从仓库获取一个镜像：`docker pull [OPTIONS] [Registry/]NAME[:TAG|@DIGEST]`
默认使用官方Registry: registry.hub.docker.com，国内的有：dl.dockerpool.com:5000
TAG默认为`latest`。
上传镜像：`docker push`

列出镜像：`docker images`。
修改镜像：`docker commit CONTAINER`，基于容器对其镜像作修改，需要指定容器的ID。
创建镜像：`docker build PATH -t="NAMESPACE/IMAGE-NAME:TAG"`，基于Dockerfile创建镜像。`--no-cache=true`禁用cache。
修改镜像标签：`docker tag`
保存／载入镜像：`docker save/load` 保存镜像及其元信息到本地文件。
删除镜像：`docker rmi` 要先删除基于这个镜像的所有容器。删除untagged镜像：`docker rmi $(docker images | grep "^<none>" | awk '{print $3}')`
查看镜像配置：`docker inspect`
查看镜像的层级：`docker history`

#### [Dockerfile](https://docs.docker.com/engine/reference/builder/)
每条指令都创建镜像的一层（都创建了新的容器并commit），不能超过127层。不同的镜像可以共享相同UUID的层级，容器运行时也可以共享镜像中只读的层级。
能写成一条指令就不要写成多条指令，用`\`多行分隔，以减少镜像的层级。
`#` 注释
`FROM` 使用作为基础的镜像，最小镜像`scratch`
`MAINTAINER` 维护者信息
`RUN` 创建过程中运行的命令，比如安装软件包
`ADD` 复制文件，可以是本地，URL，压缩包
`COPY` 复制本地文件
`EXPOSE` 向外部开放的端口
`VOLUME` 挂载数据卷
`ENV` 指定运行时环境变量
`USER` 运行容器时的用户名或UID
`CMD` 容器启动后执行的命令
`WORKDIR` 为其它RUN，CMD，ENTRYPOINT指定工作目录
`ENTRYPOINT` 容器启动后执行的命令，默认`/bin/sh -c`
`ONBUILD` 作为其它新建镜像的基础镜像时执行的指令
`LABEL` 以`[<namespace>.]<key>[=<value>]`的形式作为元信息保存

### Container
容器是镜像的运行实例。容器在镜像最上层创建自己的读写层，当容器被删除时，这层也被丢弃。
当容器中运行的程序结束时，容器终止。

创建容器：`docker create`
启动容器：`docker run IMAGE`，加上`-it`分配伪终端及输入输出；`-d`后台运行；`--rm`退出时删除容器, `--name`命名，`--net`指定网络。
启动已终止的容器：`docker start`
重启容器：`docker restart`
终止容器：`docker stop`
杀死容器：`docker kill`
查看容器的输出：`docker logs`
查看容器状态：`docker ps`，`-a`查看包括已终止的所有容器; `-q`仅列出id。
查看容器设置：`docker inspect`
查看容器进程：`docker top`
在运行的容器中执行命令：`docker exec`
连接到容器：`docker attach`，`ctrl-p,ctrl-q`可以detach而不退出shell。
导出导入容器快照：`docker export/import` 导出到快照文件（无元信息）／从文件导入为镜像。
删除容器：`docker rm`，加上`-v`同时删除数据卷（只会删除匿名的卷）；`-f`停止并删除。删除所有容器：`docker rm $(docker ps -qa)`
在容器中执行命令：`docker exec`

### Data Volume
`docker run -v [PATH/NAME:]CONTAINER-PATH[:ATTR]`: 挂载目录给容器共享使用。本地路径PATH默认`/var/lib/docker/volumes/`随机临时目录（或由NAME指定），属性：`rw`, `ro`
查看：`docker inspect`下面`Mounts`

`docker run --volumes-from CONTAINER`：挂载其它容器（不需要运行状态）的数据卷。

### Port Mapping
`docker run -P`：随机映射容器内部端口到49000-49900。
`docker run -p [IP:]hostPort:containerPort/[IP:]containerPort`：映射指定端口。默认tcp，加上`/udp`指定udp。
`docker port`：查看端口配置。

### Network
列出所有网络: `docker network ls`
查看网络：`docker network inspect NAME`
从网络中加入/移除容器：`docker network connect/disconnect NAME CONTAINER`
创建网络：`docker network create NAME` `--driver`指定驱动类型
删除网络：`docker network rm`

#### host
直接使用host网络。

#### bridge
默认虚拟网桥(bridge)设备名字`docker0`（新建`br-xxx`），每创建一个连接到上面的容器`eth0`连接到host上的网络接口`vethX`(`brctl show`), 这就是一对veth pair(用`ethtool -S`查看对应序号)。
在同一个bridge网络里的容器在同一网段可以互相内部通信（如果容器运行时指定了名字且不在默认的bridge网络上，通过daemon运行的内置的DNS服务器`127.0.0.11`，就能以容器的`name`或`net-alias`访问），但必须运行在同一host上。如果要运行在不同host上就必须利用overlay网络。
如果一个容器连接到两个不同的网络，就有两个网卡并绑定两个网段的IP地址。当容器停止时就从其网络中脱离。

`[container](eth0)----(vethX)[docker0@host]`

#### overlay
overlay网络使用[vxlan](https://datatracker.ietf.org/doc/rfc7348/)技术，端口：数据udp4789，控制tcp/udp7946。
每个容器和overlay网络都有自己的网络namespace。

加入overlay网络的host daemon启动时必须指定kv store：`--cluster-store=etcd://addr:8500`和`--cluster-advertise=eth0:2375`，指定选项`--cluster-store-opt`
可以在任意一台连到store的host上创建：`docker network create --driver overlay --subnet=10.0.9.0/24 my-net` 指定子网避免和现有网络冲突。
当有一个容器连接到overlay网络时，会在其host上自动创建一个`docker_gwbridge`网桥（代替docker0的作用，即使有多个overlay网络，也只会有一个这个网桥，但每个host都是独立的），并且容器的第一个网络接口`eth0`连接到overlay网络的网桥br0上，第二个接口`eth1`连接到这个网桥。br0上有个VTEP(vxlan1)通过host的外部网络接口连接出去。

`[container](eth1)----(vethX)[docker_gwbridge@host]`
`[container](eth0)----(vethY)[br0@host](vxlan1)----(eth0)[host]`

#### none
不配置任何网络。
手动配置：

1. `docker inspect -f '{{.State.Pid}}' cid` 启动一个`--net=none`的容器并取得其pid
1. `mkdir -p /var/run/netns && ln -s /proc/$pid/ns/net /var/run/netns/$pid` 让`ip netns`可以取得容器创建的namespace，若要创建新的`ip netns add`
1. `ip link add vethXYZ type veth peer name eth100` 创建一对veth pair，名字要唯一
1. `brctl addif docker0 vethXYZ` 将一个加入默认网桥
1. `ip link set vethXYZ up` 启动
1. `ip link set eth100 netns $pid` 将另一个加入namespace, vethXYZ在root namespace下面
1. `ip netns exec $pid ip link set dev eth100 name eth0` 改为通用名
1. `ip netns exec $pid ip link set eth0 up` 启动
1. `ip netns exec $pid ip addr add 172.17.0.99/16 dev eth0` 配置子网范围
1. `ip netns exec $pid ip route add default via 172.17.0.1` 配置默认网关

#### DNS
容器的DNS配置和host上一致(/etc/hosts, /etc/hostname, /etc/resolv.conf是`/var/lib/docker/containers/{id}/`虚拟文件不在镜像中)，并随host上自动更新（需重启）。也可以运行时用参数`--hostname`, `--dns`, `--dns-search`指定。

#### Access Control
容器通过iptables进行访问控制，daemon启动时可以用`--iptables`控制是否修改iptable，用`--icc`设置默认允许还是禁止。
用`iptables [-t nat] -nvL`查看现有规则，用`iptables [-t nat] -S`查看docker加入规则的命令。
容器和外网的通信：

* `net.ipv4.conf.all.forwarding`是否打开
* iptables的FORWOARD(DOCKER chain)规则是否允许
* 容器访问外部：SNAT/MASQUERADE，外部访问容器：DNAT（端口映射）

容器间的通信：

* 网络拓扑是否连通
* iptables的FORWOARD规则是否允许

#### iptables
作为host转发，一般判断流程：`nat-Prerouting -> filter-Forward -> nat-Postrouting`

docker0 filter:
```
-N DOCKER
-N DOCKER-ISOLATION
-A FORWARD -j DOCKER-ISOLATION
-A FORWARD -o docker0 -j DOCKER
-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A FORWARD -i docker0 ! -o docker0 -j ACCEPT
-A FORWARD -i docker0 -o docker0 -j ACCEPT
-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 9000 -j ACCEPT
-A DOCKER-ISOLATION -i br-93db485344a4 -o docker0 -j DROP
-A DOCKER-ISOLATION -i docker0 -o br-93db485344a4 -j DROP
-A DOCKER-ISOLATION -j RETURN
```
拒绝不同网段网桥的包。
接受从非docker0进入的，且从docker0出去访问9000端口的包。（外部连接容器，数据进入时）
接受从docker0出去的连接状态的包。（容器连接外部，数据返回时）
接受从docker0进入的包。（容器互连）

docker0 nat (--userland-proxy=false, [true by default](https://github.com/docker/docker/issues/14856)):
```
-N DOCKER
-A PREROUTING -m addrtype --dst-type LOCAL -j DOCKER
-A OUTPUT -m addrtype --dst-type LOCAL -j DOCKER
-A POSTROUTING -o docker0 -m addrtype --src-type LOCAL -j MASQUERADE
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
-A POSTROUTING -s 172.17.0.2/32 -d 172.17.0.2/32 -p tcp -m tcp --dport 9000 -j MASQUERADE
-A DOCKER -p tcp -m tcp --dport 9000 -j DNAT --to-destination 172.17.0.2:9000
```
从172.17.0.0/16网段出来的，且不从docker0出去的，做MASQUERADE(SNAT，伪装成出口网卡地址)。
从host发出，docker0出去的，做MASQUERADE（伪装成docker0网关地址）。
容器访问自己的端口，做MASQUERADE。
访问host 9000端口做DNAT发到172.17.0.2:9000。

### TLS
docker engine普通/TLS端口：2375/2376
swarm manager普通/TLS端口：3375/3376

#### CA
创建私钥：`openssl genrsa -out ca-priv-key.pem 2048` 查看：`openssl rsa -in ca-priv-key.pem -noout -text`
创建公钥：`openssl req -config /usr/lib/ssl/openssl.cnf -new -key ca-priv-key.pem -x509 -days 1825 -out ca.pem` 查看：`openssl x509 -in ca.pem -noout -text`

#### Node
创建私钥：`openssl genrsa -out key.pem 2048`
创建CSR(Certificate Signing Request)：`openssl req -subj "/CN=node" -new -key key.pem -out node.csr`
签发证书（将node的公钥由CA的私钥加密，防止篡改）：`openssl x509 -req -days 1825 -in node.csr -CA ca.pem -CAkey ca-priv-key.pem -CAcreateserial -out cert.pem -extensions v3_req -extfile /usr/lib/ssl/openssl.cnf`

#### Install
安装目录：`~/.certs`
安装文件：CA的公钥`ca.pem`，node的私钥`key.pem`及证书`cert.pem`。

#### Config
engine: 加入daemon选项` -H tcp://0.0.0.0:2376 --tlsverify --tlscacert=/home/ubuntu/.certs/ca.pem --tlscert=/home/ubuntu/.certs/cert.pem --tlskey=/home/ubuntu/.certs/key.pem`
swarm manager: `docker run -d -p 3376:3376 -v /home/ubuntu/.certs:/certs:ro swarm manage --tlsverify --tlscacert=/certs/ca.pem --tlscert=/certs/cert.pem --tlskey=/certs/key.pem --host=0.0.0.0:3376 token://$TOKEN`
client: `docker --tlsverify --tlscacert=/home/ubuntu/.certs/ca.pem --tlscert=/home/ubuntu/.certs/cert.pem --tlskey=/home/ubuntu/.certs/key.pem -H swarm:3376 version` 亦可以设置环境变量`DOCKER_TLS_VERIFY=1`及`DOCKER_CERT_PATH=/home/ubuntu/.certs`

### Plugins
plugin是host上的一个独立进程，作为服务器提供一组HTTP API (RPC-style JSON over HTTP)给docker daemon使用。所有从docker daemon发起的请求都是POST。
docker daemon可以有几种方式加载激活plugin（lazy，第一次使用时，通过handshake请求），文件名就作为plugin的名字：

* `.sock`文件，plugin服务监听sock，安装在`/run/docker/plugins`目录下。（优先）
* `.spec`文件，包含sock地址如`unix:///my-plugin.sock`，安装在`/etc/docker/plugins`或`/usr/lib/docker/plugins`目录。
* `.json`文件，包含plugin的详细spec信息。`TLSConfig`可选。
```
{
  "Name": "plugin-example",
  "Addr": "https://example.com/docker/plugin",
  "TLSConfig": {
    "InsecureSkipVerify": false,
    "CAFile": "/usr/shared/docker/certs/example-ca.pem",
    "CertFile": "/usr/shared/docker/certs/example-cert.pem",
    "KeyFile": "/usr/shared/docker/certs/example-key.pem",
  }
}
```

handshake:
`/Plugin.Activate`: response `{ "Implements": ["VolumeDriver"] }`，类型可以是`authz`, `VolumeDriver`, `NetworkDriver`

helpers:
https://github.com/docker/engine-api
https://github.com/docker/go-plugins-helpers

#### Volume
创建：`docker volume create -d DRIVER --name VOL-NAME`（默认driver: local）。
功能：提供一个可读写的路径给docker容器使用。
例子：https://github.com/CWSpear/local-persist

API: `/VolumeDriver.Create/Remove/Mount/Path/Unmount/Get/List`
```
type Driver interface {
	Create(Request) Response
	List(Request) Response
	Get(Request) Response
	Remove(Request) Response
	Path(Request) Response
	Mount(Request) Response
	Unmount(Request) Response
}
```

#### Network
创建：`docker network create -d DRIVER NETWORK-NAME`（默认driver: bridge）。
功能：提供诸如VXLAN, IPVLAN, MACVLAN等网络技术给docker的部署提供扩展。

API: https://github.com/docker/libnetwork/blob/master/docs/remote.md
```
type Driver interface {
	GetCapabilities() (*CapabilitiesResponse, error)
	CreateNetwork(*CreateNetworkRequest) error
	DeleteNetwork(*DeleteNetworkRequest) error
	CreateEndpoint(*CreateEndpointRequest) (*CreateEndpointResponse, error)
	DeleteEndpoint(*DeleteEndpointRequest) error
	EndpointInfo(*InfoRequest) (*InfoResponse, error)
	Join(*JoinRequest) (*JoinResponse, error)
	Leave(*LeaveRequest) error
	DiscoverNew(*DiscoveryNotification) error
	DiscoverDelete(*DiscoveryNotification) error
	ProgramExternalConnectivity(*ProgramExternalConnectivityRequest) error
	RevokeExternalConnectivity(*RevokeExternalConnectivityRequest) error
}
```

#### authz

## Swarm
### Install
`docker pull swarm`

### Cluster & Discovery
#### DockerHub（不建议生产环境使用）

1. 创建token（任意host）：`docker run --rm swarm create`
1. 加入集群（每台host）：`docker run -d swarm join --addr=ip_address:2375 token://token_id`
1. 启动manager（管理host）：`docker run -d -P swarm manage token://token_id`

如果由于虚拟机clone导致ID冲突，需删除`/etc/docker/key.json`然后重启daemon。
管理命令（任意host）：`docker run --rm swarm list token://token_id`
在集群中执行（任意host）：`docker -H manager_ip:port command`，manger地址也可以用环境变量`DOCKER_HOST`，此时命令都在集群环境中执行，比如`info`可以看到集群信息，从`ps`的NAMES可以看到容器运行在哪个node下面。

#### 文件或列表
集群host不需要join。
list: `docker run -d -P swarm manage nodes://<node_ip1:2375>,<node_ip2:2375>`
file: `docker run -d -P -v $(pwd)/cluster:/tmp/cluster swarm manage file:///tmp/cluster` 文件里nodes以行分割

#### KV Store (etcd/consul/zookeeper)
加入集群：`swarm join --addr=<node_ip:2375> etcd://<etcd_addr1>,<etcd_addr2>/<optional path prefix>`
启动manager：`swarm manage etcd://<etcd_addr1>,<etcd_addr2>/<optional path prefix>`

### Strategies
`swarm manage --strategy`, spread/binpack也考虑CPU/MEM因素。

* spread（默认）: 尽可能选择container的数目最少（不管状态如何）的那个node来运行container。
* binpack: 尽可能把所有容器放在一台node上面运行。
* random: 随机。

### Filters
`swarm manage --filter`

#### node filter

* constraint: 指定node运行容器的node条件
    * lable过滤：`-e constraint:name==node1`，label可以在daemon运行时指定：`--label name=node1`
    * 默认tags(docker info查看)过滤：`node(ID或Name)/storagedriver/executiondriver/kernelversion/operatingsystem`
    * 在`docker build`的时候也可以指定（运行时自动应用）：`--build-arg=constraint:storage==disk`。
* health: 只在`Status: Healthy`的node上运行。

#### container filter (不考虑容器状态)

* affinity: 在指定容器同一node上运行
    * ID/Name过滤：`-e affinity:container==container_name/id`
    * 镜像过滤：在具有指定镜像的node上运行，`-e affinity:image=image_name/id`；
    * 容器label过滤：`-e affinity:name=node1`，lable在容器运行时指定。
* dependency：根据容器依赖关系在同一node上运行
    * --volumes-from=container_name (shared volumes)
    * --link=container_name:alias (links)
    * --net=container:container_name (shared network stacks)
* port: 在一个node上如果一个指定的port已经被占用（即使已经stop），就选择另一个node。

#### filter expressions
`<filter-type>:<key><operator><value>`

* filter-type: affinity/constraint
* key: container/node/default tags/label
* operator: `==`/`!=`
* value: 可以用通配符和正则表达式[/regexp/](https://github.com/google/re2/wiki/Syntax)，value前面加上`~`，则是不严格匹配，找不到符合条件的node就按照strategy来。

## Machine
### Install
``curl -L https://github.com/docker/machine/releases/download/v0.6.0/docker-machine-`uname -s`-`uname -m` > /usr/local/bin/docker-machine && chmod +x /usr/local/bin/docker-machine``

### Provision
使用虚拟机：`docker-machine create --driver virtualbox default` (用装有docker的镜像[boot2docker](https://github.com/boot2docker/boot2docker)创建一个虚拟机)
使用已有host：`docker-machine create --driver generic --generic-ip-address=192.168.0.1 --generic-ssh-user=root default`
使用已有装好docker的host：`docker-machine create --drive none --url=tcp://50.134.234.20:2376 custombox` ([broken](https://github.com/docker/machine/issues/2667))
还可以使用其它云服务：[支持驱动列表](https://docs.docker.com/machine/drivers/)

使用swarm: [provision with machine](https://docs.docker.com/swarm/provision-with-machine/)
master: `docker-machine create -d virtualbox --swarm --swarm-master --swarm-discovery="consul://$(docker-machine ip keystore):8500" --engine-opt="cluster-store=consul://$(docker-machine ip keystore):8500" --engine-opt="cluster-advertise=eth0:2376" sw-master`
host: `docker-machine create -d virtualbox --swarm --swarm-discovery="consul://$(docker-machine ip keystore):8500" --engine-opt="cluster-store=consul://$(docker-machine ip keystore):8500" --engine-opt="cluster-advertise=eth0:2376" host1`

设置运行环境： `eval "$(docker-machine env default)"` （使用default作为名字，在`docker-machine`命令中可以省略），加上`env --swarm`设置swarm manager环境。

## Compose
### Install
``curl -L https://github.com/docker/compose/releases/download/1.6.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose && chmod +x /usr/local/bin/docker-compose``

### Project
一个project（默认目录名）包含一组服务，每个服务就是一个应用容器，可以运行多个实例。
实际运行容器的名字：`project_service_#`，并以`service`为`net-alias`，创建并使用`project_default`网络。

使用`docker-compose build`根据`docker-compose.yml`构建整个project。
创建（删除）相关服务：`docker-compose create/rm`
运行（停止）相关服务：`docker-compose start/stop`
启动（卸载）整个project：`docker-compose up` = build + create + start / `docker-compose down` = stop + rm

运行一个服务并执行命令：`docker-compose run`，也会运行相关服务除非加上`--no-deps`。
扩展（或收缩）服务的容器实例：`docker-compose scale SERVICE=NUM`

使用`links`配置会在`Networks.Links`下创建相应条目，如果是scale之后的实例，必须要stop/start后才能生效（BUG? restart无效）。
关于启动顺序：根据依赖顺序depends_on, links等启动，一旦开始运行就启动下一个。如果服务需要依赖连接端口监听就绪，通常做法是将ENTRYPOINT设置一个轮询脚本，而在CMD中设置要运行的命令。

### [Compose File](https://docs.docker.com/compose/compose-file) v2
`docker-compose.yml`是yaml配置文件：至少包含`build`或`image`指定构建镜像，其它指定服务的运行参数，和`docker run`的参数类似。
`docker-compose.override.yml`可以覆盖默认配置文件里的相应值，如果是其它名字或多个覆盖文件则需要用`-f`参数一起加入进来并按加入的指定顺序覆盖（单值覆盖，多值合并覆盖）。

继承(extends)：
```
web:
  extends:
    file: common-services.yml
    service: webapp

important_web:
  extends: web
  cpu_shares: 10
```

## [Kubernetes](http://kubernetes.io/)


## Reference
[docker jumpstart](http://odewahn.github.io/docker-jumpstart)
[docker practice](https://www.gitbook.io/book/yeasy/docker_practice)
[boycott docker](http://www.boycottdocker.org/)


</xmp>
<script src="js/strapdown.js"></script>
</html>
